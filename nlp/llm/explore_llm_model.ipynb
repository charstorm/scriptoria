{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring LLM Models\n",
    "\n",
    "This notebook contains the following:\n",
    "1. Dumping the model architecture in a readable format\n",
    "2. Capturing the callflow of various modules and submodule during LLM inference\n",
    "3. Visualizing the result of [2] using an awfully hacky HTML solution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import os\n",
    "import gc\n",
    "import hashlib\n",
    "from pathlib import Path\n",
    "from types import MethodType\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "HF_TOKEN = os.environ[\"HF_TOKEN\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following are a set of simple functions to explore a pytorch model. The key function is `module.named_children`. This can be applied recursively for each sub-module and their sub-modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traverse_layers(module: nn.Module, depth: int = 0) -> None:\n",
    "    for name, module in module.named_children():\n",
    "        print(\"  \" * depth + f\"{name}: {module.__class__.__name__}\")\n",
    "        traverse_layers(module, depth + 1)\n",
    "\n",
    "\n",
    "def module_to_dict(\n",
    "    module: nn.Module, depth: int = 0, with_module: bool = False\n",
    ") -> dict:\n",
    "    layers = {}\n",
    "    for name, module in module.named_children():\n",
    "        # Recursive step\n",
    "        children = module_to_dict(module, depth + 1, with_module)\n",
    "\n",
    "        layers[name] = {\n",
    "            \"depth\": depth,\n",
    "            \"type\": module.__class__.__name__,\n",
    "            \"children\": children,\n",
    "        }\n",
    "        if with_module:\n",
    "            layers[name][\"module\"] = module\n",
    "    return layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can try the above on a small model. Using `Llama-3.2-1B` here. For LLAMA models, you will need permission from Meta to access them. Otherwise you can try with some other small model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"meta-llama/Llama-3.2-1B\"\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    token=HF_TOKEN,\n",
    ")\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "module = pipe.model\n",
    "model_dict = module_to_dict(module, with_module=False)\n",
    "\n",
    "Path(\"tmp\").mkdir(parents=True, exist_ok=True)\n",
    "with open(\"tmp/model_arch.json\", \"w\") as writer:\n",
    "    json.dump(model_dict, writer, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output JSON would look like what is given below. You might want to use a decent JSON viewer (check online) to explore it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -n 20 \"tmp/model_arch.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above does not capture the flow of information in the pipeline. We can mock the `.forward()` method of all the modules to give the call information. That way, we get to see what the modules getting called in order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_log_stack = []\n",
    "\n",
    "\n",
    "def mock_forward(module: nn.Module, depth: int, name: str) -> None:\n",
    "    if hasattr(module, \"_original_forward_func\"):\n",
    "        return  # Already mocked\n",
    "\n",
    "    # Take a copy of the original forward function\n",
    "    module._original_forward_func = module.forward  # type: ignore\n",
    "\n",
    "    def new_forward(self, *args, **kwargs):\n",
    "        saved_stack = module_log_stack.copy()\n",
    "        module_log_stack.clear()\n",
    "\n",
    "        start_time = time.time()\n",
    "        output = self._original_forward_func(*args, **kwargs)\n",
    "        elapsed_time = time.time() - start_time\n",
    "\n",
    "        module_name = self.__class__.__name__\n",
    "        msg = {\n",
    "            \"depth\": depth,\n",
    "            \"name\": name,\n",
    "            \"module\": module_name,\n",
    "            \"time\": elapsed_time,\n",
    "        }\n",
    "        if module_log_stack:\n",
    "            msg[\"children\"] = module_log_stack.copy()\n",
    "\n",
    "        saved_stack.append(msg)\n",
    "        module_log_stack[:] = saved_stack\n",
    "\n",
    "        return output\n",
    "\n",
    "    # Use the wrapper `forward` function\n",
    "    module.forward = MethodType(new_forward, module)\n",
    "    # print(\"Mocked: \", str(module.__class__))\n",
    "\n",
    "\n",
    "def apply_mocking(model: nn.Module, depth: int = 0):\n",
    "    for name, module in model.named_children():\n",
    "        if hasattr(module, \"forward\"):\n",
    "            mock_forward(module, depth, name)\n",
    "        apply_mocking(module, depth + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "module = pipe.model\n",
    "apply_mocking(module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can run the text generation and `module_log_stack` will have the logs coming from all the `forward()` calls in a hierarchical way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Once upon a time\"\n",
    "module_log_stack.clear()\n",
    "output = pipe(prompt, max_length=8, do_sample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"tmp/call_logs.json\", \"w\") as fp:\n",
    "    json.dump(module_log_stack, fp, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -n20 tmp/call_logs.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a way to display the these in a structured way. Lets cook up a hacky HTML solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_color_for_key(key: str) -> str:\n",
    "    if key == \"root\":\n",
    "        return \"hsl(0%, 100%, 100%)\"\n",
    "    hash_value = int(hashlib.md5(key.encode()).hexdigest(), 16)\n",
    "    random.seed(hash_value + 5)\n",
    "    hue = random.randint(0, 360)\n",
    "    sat = random.randint(50, 100)\n",
    "    light = random.randint(80, 94)\n",
    "    return f\"hsl({hue}, {sat}%, {light}%)\"\n",
    "\n",
    "\n",
    "def generate_html(entry: dict) -> str:\n",
    "    color = get_color_for_key(entry[\"module\"])\n",
    "    style = (\n",
    "        f\"background-color: {color}; min-width: 100px; \"\n",
    "        \"font-size:1.1rem; \"\n",
    "        \"border: 1px solid #aaa; margin: 5px; \"\n",
    "        \"padding-left: 5px; color: #000;\"\n",
    "    )\n",
    "    children = entry.get(\"children\", [])\n",
    "    children_html = \"\\n\".join(generate_html(child) for child in children)\n",
    "    return (\n",
    "        f'<div style=\"{style}\">'\n",
    "        f'{entry[\"name\"]} {entry[\"module\"]} ({entry[\"time\"]:.4f}s){children_html}'\n",
    "        '</div>'\n",
    "    )\n",
    "\n",
    "children = json.loads(Path(\"tmp/call_logs.json\").read_text())\n",
    "root = {\"name\": \"root\", \"module\": \"root\", \"children\": children, \"time\": float(\"NAN\")}\n",
    "html_content = generate_html(root)\n",
    "Path(\"tmp/call_logs_viz.html\").write_text(f\"{html_content}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The visualization is saved as HTML in the previous step. We can now display it inside the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "with open(\"tmp/call_logs_viz.html\", \"r\", encoding=\"utf-8\") as f:\n",
    "    html_content = f.read()\n",
    "\n",
    "HTML(\n",
    "    f\"\"\"\n",
    "    <div style=\"max-height: 950px; overflow-y: auto; width: 600px;\">\n",
    "    {html_content}\n",
    "    </div>\"\"\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
